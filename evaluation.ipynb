{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE LOSS: 0.007594614289700985\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from metrics import acc\n",
    "\n",
    "from data import get_training_and_validation_data\n",
    "from autoencoder import Autoencoder, VariationalAutoencoder, CategoricalAutoencoder, ConvolutionalCategoricalAutoencoder\n",
    "\n",
    "model_id = 'PRZG24RVB6'\n",
    "model_config = json.load(open(Path('models') / model_id / 'config.json', 'r'))\n",
    "dataset_id = model_config['dataset_id']\n",
    "model_type = model_config['model']\n",
    "\n",
    "X_train, y_train, X_val, y_val = get_training_and_validation_data(\n",
    "    Path('processed_data'), dataset_id, balanced=True)\n",
    "# X_mean, X_std = X_train.mean(), X_train.std()\n",
    "# X_train -= X_mean\n",
    "# X_train /= X_std\n",
    "# X_val -= X_mean\n",
    "# X_val /= X_std\n",
    "\n",
    "X_min, X_max = X_train.min(), X_train.max()\n",
    "X_train -= X_min\n",
    "X_train /= (X_max - X_min)\n",
    "X_val -= X_min\n",
    "X_val /= (X_max - X_min)\n",
    "X_train_tensor = torch.from_numpy(X_train).to(torch.float32)\n",
    "X_val_tensor = torch.from_numpy(X_val).to(torch.float32)\n",
    "\n",
    "if model_config['model'] == 'vae':\n",
    "    model = VariationalAutoencoder\n",
    "elif model_config['model'] == 'cae':\n",
    "    model = CategoricalAutoencoder\n",
    "elif model_config['model'] == 'convcae':\n",
    "    model = ConvolutionalCategoricalAutoencoder\n",
    "else:\n",
    "    model = Autoencoder\n",
    "\n",
    "autoencoder = model(input_dim=X_train.shape[1], **model_config)\n",
    "autoencoder.load_state_dict(torch.load(Path('models') / model_id / 'ae.pth'))\n",
    "autoencoder.eval()\n",
    "\n",
    "if model_type == 'cae' or model_type == 'convcae':\n",
    "    p = autoencoder.encode(X_train_tensor)\n",
    "    X_train_enc = autoencoder.reparameterize(p, temperature=model_config['temperature'])\n",
    "elif model_type == 'vae':\n",
    "    X_train_mu, X_train_log = autoencoder.encode(X_train_tensor)\n",
    "    X_train_enc = autoencoder.reparameterize(X_train_mu, X_train_log)\n",
    "else:\n",
    "    X_train_enc = autoencoder.encode(X_train_tensor)\n",
    "X_train_rec = autoencoder.decode(X_train_enc)\n",
    "print('MSE LOSS:', torch.nn.functional.mse_loss(X_train_tensor, X_train_rec).item())\n",
    "X_train_rec = X_train_rec.detach().numpy()\n",
    "X_train_enc = X_train_enc.detach().numpy()\n",
    "\n",
    "if model_type == 'cae' or model_type == 'convcae':\n",
    "    p = autoencoder.encode(X_val_tensor)\n",
    "    X_val_enc = autoencoder.reparameterize(p, temperature=model_config['temperature'])\n",
    "elif model_type == 'vae':\n",
    "    X_val_mu, X_val_log = autoencoder.encode(X_val_tensor)\n",
    "    X_val_enc = autoencoder.reparameterize(X_val_mu, X_val_log)\n",
    "else:\n",
    "    X_val_enc = autoencoder.encode(X_val_tensor)\n",
    "X_val_rec = autoencoder.decode(X_val_enc).detach().numpy()\n",
    "X_val_enc = X_val_enc.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X_train_enc, columns=[f'Dim_{i+1}' for i in range(X_train_enc.shape[1])])\n",
    "data['Class'] = y_train\n",
    "\n",
    "# Plot violin plots for each dimension\n",
    "for column in data.columns[:-1]:  # Exclude the 'Class' column for the plots\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(x='Class', y=column, data=data, hue='Class', palette='muted', legend=False)\n",
    "    plt.title(f'Violin Plot of {column}')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2525083304.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print((sample - rec_sample)**2.mean())\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "samples = {}\n",
    "for class_label in range(4):\n",
    "    indices = np.where(y_train == class_label)[0]\n",
    "    random_index = np.random.choice(indices)\n",
    "    samples[class_label] = X_train[random_index], X_train_rec[random_index]\n",
    "\n",
    "for class_label, (sample, rec_sample) in samples.items():\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(sample, color='b')\n",
    "    plt.plot(rec_sample, color='r')\n",
    "    print(((sample - rec_sample)**2).mean())\n",
    "    plt.title(f\"Class {class_label}\")\n",
    "    plt.grid(True)\n",
    "    # plt.ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2118\n",
      "           1       0.83      0.83      0.83     15035\n",
      "           2       1.00      0.58      0.73      9923\n",
      "           3       0.94      0.97      0.96      1555\n",
      "\n",
      "    accuracy                           0.69     28631\n",
      "   macro avg       0.69      0.59      0.63     28631\n",
      "weighted avg       0.83      0.69      0.74     28631\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timodw/.pyenv/versions/3.11.7/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "mean, std = X_train_enc.mean(), X_train_enc.std()\n",
    "X_train_enc -= mean\n",
    "X_train_enc /= std\n",
    "X_val_enc -= mean\n",
    "X_val_enc /= std\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X_train_enc)\n",
    "y_pred = kmeans.predict(X_val_enc)\n",
    "_, label_mapping = acc(y_val, y_pred, return_mapping=True)\n",
    "y_pred = np.vectorize(label_mapping.get)(y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2118\n",
      "           1       0.86      0.90      0.88     15035\n",
      "           2       1.00      0.77      0.87      9923\n",
      "           3       0.95      0.94      0.95      1555\n",
      "\n",
      "    accuracy                           0.79     28631\n",
      "   macro avg       0.70      0.65      0.67     28631\n",
      "weighted avg       0.85      0.79      0.81     28631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=4)\n",
    "gmm.fit(X_train_enc)\n",
    "y_pred = gmm.predict(X_val_enc)\n",
    "_, label_mapping = acc(y_val, y_pred, return_mapping=True)\n",
    "y_pred = np.vectorize(label_mapping.get)(y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "from tqdm import tqdm\n",
    "\n",
    "@njit\n",
    "def njit_dtw(s1, s2):\n",
    "    len_s1 = len(s1)\n",
    "    len_s2 = len(s2)\n",
    "    mat_d = np.full((len_s1 + 1, len_s2 + 1), np.inf, dtype=np.float64)\n",
    "    mat_d[0, 0] = 0.0\n",
    "\n",
    "    for i in range(1, len_s1 + 1):\n",
    "        for j in range(1, len_s2 + 1):\n",
    "            d = (s1[i - 1] - s2[j - 1])**2\n",
    "            mat_d[i, j] = d + np.min(np.array([mat_d[i-1, j], mat_d[i, j-1], mat_d[i-1, j-1]]))\n",
    "    \n",
    "    return np.sqrt(mat_d[len_s1, len_s2])\n",
    "\n",
    "_ = njit_dtw(np.random.randn(100), np.random.randn(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 100) (array([0, 1, 2, 3]), array([ 25, 193, 239,  43]))\n"
     ]
    }
   ],
   "source": [
    "from data import load_dataset\n",
    "\n",
    "X, y = load_dataset(Path('processed_data'), dataset_id='RTAGXFQJ4T')\n",
    "X, y = X[0][:, :, 0], y[0]\n",
    "indices = np.random.choice(len(X), 500)\n",
    "X, y = X[indices], y[indices]\n",
    "print(X.shape, np.unique(y, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:41<00:00, 12.06it/s]\n"
     ]
    }
   ],
   "source": [
    "n = len(X)\n",
    "distance_matrix = np.zeros((n, n))\n",
    "for i in tqdm(range(n)):\n",
    "    for j in range(i, n):\n",
    "        distance = njit_dtw(X[i], X[j])\n",
    "        distance_matrix[i, j] = distance\n",
    "        distance_matrix[j, i] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timodw/.pyenv/versions/3.11.7/lib/python3.11/site-packages/sklearn/cluster/_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([  2,   5,   2,  19,   3,   1,   1, 454,  11,   2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from collections import defaultdict\n",
    "\n",
    "def cluster_time_series(distance_matrix, n_clusters=None):\n",
    "    clustering_model = AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage='average')\n",
    "    labels = clustering_model.fit_predict(distance_matrix)\n",
    "    return labels\n",
    "\n",
    "clusters = cluster_time_series(distance_matrix, n_clusters=10)\n",
    "cluster_label_mapping = defaultdict(set)\n",
    "for label, cluster in zip(y, clusters):\n",
    "    cluster_label_mapping[cluster].add(label)\n",
    "\n",
    "for i in range(len(cluster_label_mapping)):\n",
    "    print(f\"Cluster {i} -> {cluster_label_mapping[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import find_k_nearest_neighbors, generate_synthetic_samples\n",
    "from collections import Counter\n",
    "\n",
    "def custom_smote(time_series_data, cluster_labels, true_labels, k=5, n_samples_ratio=1.0):\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    synthetic_data = []\n",
    "    synthetic_labels = []\n",
    "\n",
    "    # Determine class distribution\n",
    "    class_counter = Counter(cluster_labels)\n",
    "    max_samples = max(class_counter.values())\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        # Get data points and their true labels in the current cluster\n",
    "        cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "        cluster_data = time_series_data[cluster_indices]\n",
    "        cluster_true_labels = np.array(true_labels)[cluster_indices]\n",
    "\n",
    "        # Find k-nearest neighbors for data in the cluster\n",
    "        _, k_neighbors = find_k_nearest_neighbors(cluster_data, k)\n",
    "\n",
    "        for class_label in class_counter:\n",
    "            # Data points of the current class in the cluster\n",
    "            class_indices = [i for i, lbl in enumerate(cluster_true_labels) if lbl == class_label]\n",
    "            class_data = cluster_data[class_indices]\n",
    "            \n",
    "            if len(class_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Determine the number of samples to generate\n",
    "            n_samples = max_samples - class_counter[class_label]\n",
    "            \n",
    "            if n_samples <= 0:\n",
    "                continue\n",
    "            \n",
    "            # Generate synthetic samples\n",
    "            synthetic_samples = generate_synthetic_samples(class_data.reshape(len(class_data), -1), k_neighbors[class_indices], n_samples)\n",
    "            \n",
    "            # Append synthetic samples and their corresponding true labels\n",
    "            synthetic_data.append(synthetic_samples)\n",
    "            synthetic_labels.extend([class_label] * n_samples)\n",
    "    \n",
    "    # Reshape synthetic data to the original time-series shape\n",
    "    if synthetic_data:\n",
    "        synthetic_data = np.vstack(synthetic_data).reshape(-1, time_series_data.shape[1], time_series_data.shape[2])\n",
    "        balanced_data = np.concatenate((time_series_data, synthetic_data))\n",
    "        balanced_labels = np.concatenate((true_labels, synthetic_labels))\n",
    "    else:\n",
    "        balanced_data = time_series_data\n",
    "        balanced_labels = true_labels\n",
    "\n",
    "    return balanced_data, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timodw/.pyenv/versions/3.11.7/lib/python3.11/site-packages/sklearn/cluster/_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m clusters \u001b[38;5;241m=\u001b[39m cluster_time_series(distance_matrix, n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcustom_smote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mcustom_smote\u001b[0;34m(time_series_data, cluster_labels, true_labels, k, n_samples_ratio)\u001b[0m\n\u001b[1;32m     17\u001b[0m cluster_true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(true_labels)[cluster_indices]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Find k-nearest neighbors for data in the cluster\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m _, k_neighbors \u001b[38;5;241m=\u001b[39m \u001b[43mfind_k_nearest_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_label \u001b[38;5;129;01min\u001b[39;00m class_counter:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Data points of the current class in the cluster\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     class_indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, lbl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cluster_true_labels) \u001b[38;5;28;01mif\u001b[39;00m lbl \u001b[38;5;241m==\u001b[39m class_label]\n",
      "File \u001b[0;32m~/IDLab/time_series_preprocessing/utils.py:7\u001b[0m, in \u001b[0;36mfind_k_nearest_neighbors\u001b[0;34m(X, k)\u001b[0m\n\u001b[1;32m      5\u001b[0m neighbors \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m      6\u001b[0m neighbors\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m----> 7\u001b[0m distances, indices \u001b[38;5;241m=\u001b[39m \u001b[43mneighbors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distances, indices\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/sklearn/neighbors/_base.py:808\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    806\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    809\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected n_neighbors <= n_samples, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but n_samples = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, n_neighbors = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[1;32m    811\u001b[0m     )\n\u001b[1;32m    813\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    814\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 5"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "clusters = cluster_time_series(distance_matrix, n_clusters=10)\n",
    "custom_smote(X, clusters, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timodw/.pyenv/versions/3.11.7/lib/python3.11/site-packages/sklearn/cluster/_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The target 'y' needs to have more than 1 class. Got 1 class instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE()\n\u001b[1;32m     15\u001b[0m cluster_data_reshaped \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(cluster_data)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(cluster_data), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_data_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_true_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m balanced_data\u001b[38;5;241m.\u001b[39mextend(X_resampled\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(X_resampled), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     19\u001b[0m balanced_labels\u001b[38;5;241m.\u001b[39mextend(y_resampled)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/imblearn/base.py:108\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_sampling_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampling_type\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[1;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    116\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/imblearn/utils/_validation.py:516\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[0;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_type\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAMPLING_KIND\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m     )\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe target \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m needs to have more than 1 class. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y)\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m class instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbypass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sampling_strategy\n",
      "\u001b[0;31mValueError\u001b[0m: The target 'y' needs to have more than 1 class. Got 1 class instead"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "balanced_data = []\n",
    "balanced_labels = []\n",
    "\n",
    "clusters = cluster_time_series(distance_matrix, n_clusters=10)\n",
    "\n",
    "unique_clusters = np.unique(clusters)\n",
    "for cluster_label in unique_clusters:\n",
    "    cluster_indices = [i for i, lbl in enumerate(clusters) if lbl == cluster_label]\n",
    "    cluster_data = [X[i] for i in cluster_indices]\n",
    "    cluster_true_labels = [y[i] for i in cluster_indices]\n",
    "\n",
    "    smote = SMOTE()\n",
    "    cluster_data_reshaped = np.array(cluster_data).reshape(len(cluster_data), -1)\n",
    "    X_resampled, y_resampled = smote.fit_resample(cluster_data_reshaped, cluster_true_labels)\n",
    "\n",
    "    balanced_data.extend(X_resampled.reshape(len(X_resampled), -1, X[0].shape[1]))\n",
    "    balanced_labels.extend(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
